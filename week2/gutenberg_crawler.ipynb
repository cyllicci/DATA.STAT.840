{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\EmmaK/nltk_data', 'c:\\\\Users\\\\EmmaK\\\\anaconda3\\\\envs\\\\dataml100\\\\nltk_data', 'c:\\\\Users\\\\EmmaK\\\\anaconda3\\\\envs\\\\dataml100\\\\share\\\\nltk_data', 'c:\\\\Users\\\\EmmaK\\\\anaconda3\\\\envs\\\\dataml100\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\EmmaK\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data', 'C:\\\\Users\\\\EmmaK\\\\nltk_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\EmmaK\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\EmmaK\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "print(nltk.data.path)\n",
    "\n",
    "# Create a directory for NLTK data if it doesn't exist\n",
    "nltk_data_dir = os.path.join(os.path.expanduser(\"~\"), \"nltk_data\")\n",
    "if not os.path.exists(nltk_data_dir):\n",
    "    os.makedirs(nltk_data_dir)\n",
    "\n",
    "# Append this directory to NLTK data path\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Download the resources again\n",
    "nltk.download('punkt', download_dir=nltk_data_dir)\n",
    "nltk.download('wordnet', download_dir=nltk_data_dir)\n",
    "\n",
    "Gutenberg_home_page_url = 'https://www.gutenberg.org'\n",
    "Gutenberg_top_page_url = Gutenberg_home_page_url + '/browse/scores/top'\n",
    "\n",
    "if not os.path.exists(\"downloaded_books\"):\n",
    "    os.makedirs(\"downloaded_books\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def getpagetext(parsedpage):\n",
    "    scriptelements=parsedpage.find_all('script')\n",
    "    for scriptelement in scriptelements:\n",
    "        scriptelement.extract()\n",
    "    pagetext=parsedpage.get_text()\n",
    "    return pagetext\n",
    "\n",
    "def parse_webpage(url):\n",
    "    try:\n",
    "        response=requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        parsed_html=bs4.BeautifulSoup(response.content,'html.parser')\n",
    "        return parsed_html\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetcing {url}: {e}\" )\n",
    "        return None\n",
    "\n",
    "def extract_actual_book_content(read_online_url, book_title):\n",
    "    parsed_html = parse_webpage(read_online_url)\n",
    "    if parsed_html is None:\n",
    "        return \"\"\n",
    "    full_text = getpagetext(parsed_html)\n",
    "    HEADER_TEXT_MARKER = \"*** START OF THE PROJECT GUTENBERG EBOOK \" + book_title.upper() + \" ***\"\n",
    "    FOOTER_TEXT_MARKER = \"*** END OF THE PROJECT GUTENBERG EBOOK \" + book_title.upper() + \" ***\"\n",
    "    start_index = full_text.find(HEADER_TEXT_MARKER) + len(HEADER_TEXT_MARKER)\n",
    "    end_index = full_text.find(FOOTER_TEXT_MARKER)\n",
    "    return full_text[start_index:end_index].strip()\n",
    "\n",
    "def save_text_to_file(author, title, content):\n",
    "    clean_title = ''.join(c for c in title if c.isalnum() or c.isspace()).replace(' ', '_')\n",
    "    file_path = os.path.join(\"downloaded_books\", f\"{clean_title}\")\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(content)\n",
    "        print(f\"saved {title} by {author} to {file_path}\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error saving {title} by {author} to {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books that will be downloaded:\n",
      "1. Author: Shelley, Mary Wollstonecraft, 1797-1851, Title: Frankenstein; Or, The Modern Prometheus\n",
      "2. Author: Shakespeare, William, 1564-1616, Title: Romeo and Juliet\n",
      "3. Author: Austen, Jane, 1775-1817, Title: Pride and Prejudice\n",
      "4. Author: Melville, Herman, 1819-1891, Title: Moby Dick; Or, The Whale\n",
      "5. Author: Eliot, George, 1819-1880, Title: Middlemarch\n",
      "6. Author: Shakespeare, William, 1564-1616, Title: The Complete Works of William Shakespeare\n",
      "7. Author: Forster, E. M. (Edward Morgan), 1879-1970, Title: A Room with a View\n",
      "8. Author: Carroll, Lewis, 1832-1898, Title: Alice's Adventures in Wonderland\n",
      "9. Author: Alcott, Louisa May, 1832-1888, Title: Little Women; Or, Meg, Jo, Beth, and Amy\n",
      "10. Author: Von Arnim, Elizabeth, 1866-1941, Title: The Enchanted April\n",
      "11. Author: Montgomery, L. M. (Lucy Maud), 1874-1942, Title: The Blue Castle: a novel\n",
      "12. Author: Hawthorne, Nathaniel, 1804-1864, Title: The Scarlet Letter\n",
      "13. Author: Smollett, T. (Tobias), 1721-1771, Title: The Adventures of Ferdinand Count Fathom — Complete\n",
      "14. Author: Gaskell, Elizabeth Cleghorn, 1810-1865, Title: Cranford\n",
      "15. Author: Smollett, T. (Tobias), 1721-1771, Title: The Expedition of Humphry Clinker\n",
      "16. Author: Fielding, Henry, 1707-1754, Title: History of Tom Jones, a Foundling\n",
      "17. Author: Smollett, T. (Tobias), 1721-1771, Title: The Adventures of Roderick Random\n",
      "18. Author: Wagner, Richard, 1813-1883, Title: My Life — Volume 1\n",
      "19. Author: Dumas, Alexandre, 1802-1870, Title: Twenty years after\n",
      "20. Author: Ibsen, Henrik, 1828-1906, Title: A Doll's House : a play\n",
      "\n",
      "Downloading book 1/20: Frankenstein; Or, The Modern Prometheus by Shelley, Mary Wollstonecraft, 1797-1851\n",
      "saved Frankenstein; Or, The Modern Prometheus by Shelley, Mary Wollstonecraft, 1797-1851 to downloaded_books\\Frankenstein_Or_The_Modern_Prometheus\n",
      "Downloading book 2/20: Romeo and Juliet by Shakespeare, William, 1564-1616\n",
      "saved Romeo and Juliet by Shakespeare, William, 1564-1616 to downloaded_books\\Romeo_and_Juliet\n",
      "Downloading book 3/20: Pride and Prejudice by Austen, Jane, 1775-1817\n",
      "saved Pride and Prejudice by Austen, Jane, 1775-1817 to downloaded_books\\Pride_and_Prejudice\n",
      "Downloading book 4/20: Moby Dick; Or, The Whale by Melville, Herman, 1819-1891\n",
      "saved Moby Dick; Or, The Whale by Melville, Herman, 1819-1891 to downloaded_books\\Moby_Dick_Or_The_Whale\n",
      "Downloading book 5/20: Middlemarch by Eliot, George, 1819-1880\n",
      "saved Middlemarch by Eliot, George, 1819-1880 to downloaded_books\\Middlemarch\n",
      "Downloading book 6/20: The Complete Works of William Shakespeare by Shakespeare, William, 1564-1616\n",
      "saved The Complete Works of William Shakespeare by Shakespeare, William, 1564-1616 to downloaded_books\\The_Complete_Works_of_William_Shakespeare\n",
      "Downloading book 7/20: A Room with a View by Forster, E. M. (Edward Morgan), 1879-1970\n",
      "saved A Room with a View by Forster, E. M. (Edward Morgan), 1879-1970 to downloaded_books\\A_Room_with_a_View\n",
      "Downloading book 8/20: Alice's Adventures in Wonderland by Carroll, Lewis, 1832-1898\n",
      "saved Alice's Adventures in Wonderland by Carroll, Lewis, 1832-1898 to downloaded_books\\Alices_Adventures_in_Wonderland\n",
      "Downloading book 9/20: Little Women; Or, Meg, Jo, Beth, and Amy by Alcott, Louisa May, 1832-1888\n",
      "saved Little Women; Or, Meg, Jo, Beth, and Amy by Alcott, Louisa May, 1832-1888 to downloaded_books\\Little_Women_Or_Meg_Jo_Beth_and_Amy\n",
      "Downloading book 10/20: The Enchanted April by Von Arnim, Elizabeth, 1866-1941\n",
      "saved The Enchanted April by Von Arnim, Elizabeth, 1866-1941 to downloaded_books\\The_Enchanted_April\n",
      "Downloading book 11/20: The Blue Castle: a novel by Montgomery, L. M. (Lucy Maud), 1874-1942\n",
      "saved The Blue Castle: a novel by Montgomery, L. M. (Lucy Maud), 1874-1942 to downloaded_books\\The_Blue_Castle_a_novel\n",
      "Downloading book 12/20: The Scarlet Letter by Hawthorne, Nathaniel, 1804-1864\n",
      "saved The Scarlet Letter by Hawthorne, Nathaniel, 1804-1864 to downloaded_books\\The_Scarlet_Letter\n",
      "Downloading book 13/20: The Adventures of Ferdinand Count Fathom — Complete by Smollett, T. (Tobias), 1721-1771\n",
      "saved The Adventures of Ferdinand Count Fathom — Complete by Smollett, T. (Tobias), 1721-1771 to downloaded_books\\The_Adventures_of_Ferdinand_Count_Fathom__Complete\n",
      "Downloading book 14/20: Cranford by Gaskell, Elizabeth Cleghorn, 1810-1865\n",
      "saved Cranford by Gaskell, Elizabeth Cleghorn, 1810-1865 to downloaded_books\\Cranford\n",
      "Downloading book 15/20: The Expedition of Humphry Clinker by Smollett, T. (Tobias), 1721-1771\n",
      "saved The Expedition of Humphry Clinker by Smollett, T. (Tobias), 1721-1771 to downloaded_books\\The_Expedition_of_Humphry_Clinker\n",
      "Downloading book 16/20: History of Tom Jones, a Foundling by Fielding, Henry, 1707-1754\n",
      "saved History of Tom Jones, a Foundling by Fielding, Henry, 1707-1754 to downloaded_books\\History_of_Tom_Jones_a_Foundling\n",
      "Downloading book 17/20: The Adventures of Roderick Random by Smollett, T. (Tobias), 1721-1771\n",
      "saved The Adventures of Roderick Random by Smollett, T. (Tobias), 1721-1771 to downloaded_books\\The_Adventures_of_Roderick_Random\n",
      "Downloading book 18/20: My Life — Volume 1 by Wagner, Richard, 1813-1883\n",
      "saved My Life — Volume 1 by Wagner, Richard, 1813-1883 to downloaded_books\\My_Life__Volume_1\n",
      "Downloading book 19/20: Twenty years after by Dumas, Alexandre, 1802-1870\n",
      "saved Twenty years after by Dumas, Alexandre, 1802-1870 to downloaded_books\\Twenty_years_after\n",
      "Downloading book 20/20: A Doll's House : a play by Ibsen, Henrik, 1828-1906\n",
      "saved A Doll's House : a play by Ibsen, Henrik, 1828-1906 to downloaded_books\\A_Dolls_House__a_play\n"
     ]
    }
   ],
   "source": [
    "def crawl_ebook(relative_link, author, title):\n",
    "    e_book_url = Gutenberg_home_page_url + relative_link\n",
    "    parsed_html = parse_webpage(e_book_url)\n",
    "\n",
    "    read_online_link = parsed_html.find('a', title='Read online')['href']\n",
    "    actual_content = extract_actual_book_content(Gutenberg_home_page_url + read_online_link, title)\n",
    "    save_text_to_file(author, title, actual_content)\n",
    "\n",
    "def get_author_and_title(relative_link):\n",
    "    e_book_url = Gutenberg_home_page_url + relative_link\n",
    "    parsed_html = parse_webpage(e_book_url)\n",
    "\n",
    "    if parsed_html is None:\n",
    "        return \"Unknown Author\", \"Unknown Title\"\n",
    "\n",
    "    try:\n",
    "        book_author = parsed_html.find('a', itemprop=\"creator\").text.strip()\n",
    "        book_title = parsed_html.find('td', itemprop=\"headline\").text.strip()\n",
    "    except AttributeError:\n",
    "        print(f\"Error parsing author or title for {relative_link}\")\n",
    "        return \"Unknown Author\", \"Unknown Title\"\n",
    "    \n",
    "    return book_author, book_title\n",
    "\n",
    "def print_book_list(books):\n",
    "    for idx, (author, title) in enumerate(books, 1):\n",
    "        print(f\"{idx}. Author: {author}, Title: {title}\")\n",
    "\n",
    "def gutenberg_top_k_ebook_crawler(top_page_url, k):\n",
    "    parsed_html = parse_webpage(top_page_url)\n",
    "\n",
    "    books_last_30_header = parsed_html.find('h2', id='books-last30')\n",
    "    book_list = books_last_30_header.find_next('ol')\n",
    "    book_items = book_list.find_all('li')\n",
    "    e_book_links = []\n",
    "    for book_item in book_items[0:k]:\n",
    "        a_element = book_item.find_next('a')\n",
    "        e_book_links.append(a_element['href'])\n",
    "\n",
    "    books = [get_author_and_title(link) for link in e_book_links]\n",
    "    \n",
    "    print(\"Books that will be downloaded:\")\n",
    "    print_book_list(books)\n",
    "\n",
    "    print()\n",
    "\n",
    "    for i, (link, (author, title)) in enumerate(zip(e_book_links, books)):\n",
    "        print(f\"Downloading book {i+1}/{k}: {title} by {author}\")\n",
    "        crawl_ebook(link, author, title)\n",
    "\n",
    "gutenberg_top_k_ebook_crawler(Gutenberg_top_page_url, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 words in the downloaded books:\n",
      "the: 153898\n",
      "of: 97619\n",
      "to: 96664\n",
      "and: 96274\n",
      "a: 94100\n",
      "I: 70335\n",
      "in: 54990\n",
      "that: 42800\n",
      "wa: 36177\n",
      "his: 35919\n",
      "he: 34156\n",
      "with: 32679\n",
      "you: 32406\n",
      "it: 31904\n",
      "my: 30270\n",
      "her: 29121\n",
      "not: 28712\n",
      "for: 28057\n",
      "had: 26241\n",
      "is: 24019\n",
      "be: 23400\n",
      "me: 21275\n",
      "s: 20157\n",
      "have: 20037\n",
      "him: 19227\n",
      "at: 19165\n",
      "this: 18923\n",
      "she: 18916\n",
      "which: 18088\n",
      "on: 16878\n",
      "by: 16797\n",
      "but: 16316\n",
      "all: 14619\n",
      "so: 14607\n",
      "from: 12902\n",
      "your: 12298\n",
      "The: 12162\n",
      "And: 11931\n",
      "will: 11124\n",
      "would: 11090\n",
      "said: 10780\n",
      "no: 10226\n",
      "an: 9861\n",
      "were: 9823\n",
      "one: 9811\n",
      "who: 9775\n",
      "are: 9752\n",
      "they: 9257\n",
      "we: 9116\n",
      "if: 8682\n",
      "do: 8533\n",
      "or: 8249\n",
      "been: 8176\n",
      "what: 8159\n",
      "more: 8153\n",
      "their: 7830\n",
      "when: 7642\n",
      "But: 7625\n",
      "them: 7582\n",
      "very: 7158\n",
      "than: 6933\n",
      "there: 6838\n",
      "now: 6834\n",
      "He: 6833\n",
      "could: 6778\n",
      "our: 6728\n",
      "out: 6434\n",
      "man: 6425\n",
      "some: 6362\n",
      "time: 6244\n",
      "up: 6125\n",
      "such: 6078\n",
      "upon: 6056\n",
      "shall: 6053\n",
      "good: 6029\n",
      "should: 5965\n",
      "d: 5914\n",
      "did: 5904\n",
      "can: 5873\n",
      "know: 5835\n",
      "thou: 5796\n",
      "any: 5687\n",
      "am: 5659\n",
      "like: 5647\n",
      "into: 5636\n",
      "then: 5528\n",
      "much: 5282\n",
      "say: 5190\n",
      "It: 5075\n",
      "must: 4988\n",
      "little: 4941\n",
      "To: 4900\n",
      "come: 4853\n",
      "t: 4787\n",
      "make: 4770\n",
      "other: 4728\n",
      "never: 4613\n",
      "see: 4613\n",
      "well: 4609\n",
      "u: 4576\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_lemmatize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum()]  # Ignore punctuation\n",
    "    return lemmatized_tokens\n",
    "\n",
    "def process_books(directory=\"downloaded_books\"):\n",
    "    unified_vocabulary = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                lemmatized_tokens = tokenize_and_lemmatize(text)\n",
    "                for token in lemmatized_tokens:\n",
    "                    unified_vocabulary[token] = unified_vocabulary.get(token, 0) + 1\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: {filename} not found in {directory}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "    return unified_vocabulary\n",
    "\n",
    "# Process the books and create a unified vocabulary\n",
    "vocabulary = process_books()\n",
    "\n",
    "# Sort and display the top 100 words by frequency\n",
    "top_100_words = sorted(vocabulary.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "print(\"Top 100 words in the downloaded books:\")\n",
    "for word, freq in top_100_words:\n",
    "    print(f\"{word}: {freq}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataml100",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
